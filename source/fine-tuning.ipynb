{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:04.599106Z",
     "iopub.status.busy": "2025-07-31T13:31:04.598563Z",
     "iopub.status.idle": "2025-07-31T13:31:49.115235Z",
     "shell.execute_reply": "2025-07-31T13:31:49.114634Z",
     "shell.execute_reply.started": "2025-07-31T13:31:04.599075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 13:31:30.692104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753968691.065047      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753968691.168845      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    RobertaTokenizer, RobertaForSequenceClassification,\n",
    "    Trainer, TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:49.116926Z",
     "iopub.status.busy": "2025-07-31T13:31:49.116382Z",
     "iopub.status.idle": "2025-07-31T13:31:50.170350Z",
     "shell.execute_reply": "2025-07-31T13:31:50.169801Z",
     "shell.execute_reply.started": "2025-07-31T13:31:49.116902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load preprocessed dataset \n",
    "data = pd.read_csv('/kaggle/input/pretrained-data/preprocessed_results.csv')\n",
    "data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:50.171703Z",
     "iopub.status.busy": "2025-07-31T13:31:50.171400Z",
     "iopub.status.idle": "2025-07-31T13:31:50.208857Z",
     "shell.execute_reply": "2025-07-31T13:31:50.208352Z",
     "shell.execute_reply.started": "2025-07-31T13:31:50.171678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['sentiment'])\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:50.210696Z",
     "iopub.status.busy": "2025-07-31T13:31:50.210312Z",
     "iopub.status.idle": "2025-07-31T13:31:51.313481Z",
     "shell.execute_reply": "2025-07-31T13:31:51.312735Z",
     "shell.execute_reply.started": "2025-07-31T13:31:50.210678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save datasets to CSV files\n",
    "os.makedirs('/kaggle/working/datasets', exist_ok=True)\n",
    "train_data.to_csv('/kaggle/working/datasets/train_data.csv', index=False)\n",
    "val_data.to_csv('/kaggle/working/datasets/val_data.csv', index=False)\n",
    "test_data.to_csv('/kaggle/working/datasets/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:51.314700Z",
     "iopub.status.busy": "2025-07-31T13:31:51.314219Z",
     "iopub.status.idle": "2025-07-31T13:31:51.653227Z",
     "shell.execute_reply": "2025-07-31T13:31:51.652446Z",
     "shell.execute_reply.started": "2025-07-31T13:31:51.314675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_data[['preprocessed_tokens', 'sentiment']].rename(columns={'preprocessed_tokens': 'text', 'sentiment': 'labels'})),\n",
    "    'valid': Dataset.from_pandas(val_data[['preprocessed_tokens', 'sentiment']].rename(columns={'preprocessed_tokens': 'text', 'sentiment': 'labels'})),\n",
    "    'test': Dataset.from_pandas(test_data[['preprocessed_tokens', 'sentiment']].rename(columns={'preprocessed_tokens': 'text', 'sentiment': 'labels'})),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:51.654330Z",
     "iopub.status.busy": "2025-07-31T13:31:51.654078Z",
     "iopub.status.idle": "2025-07-31T13:31:51.658897Z",
     "shell.execute_reply": "2025-07-31T13:31:51.658220Z",
     "shell.execute_reply.started": "2025-07-31T13:31:51.654308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    metric_acc = evaluate.load(\"accuracy\")\n",
    "    metric_f1 = evaluate.load(\"f1\")\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = metric_acc.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:51.660047Z",
     "iopub.status.busy": "2025-07-31T13:31:51.659814Z",
     "iopub.status.idle": "2025-07-31T13:31:51.681832Z",
     "shell.execute_reply": "2025-07-31T13:31:51.681091Z",
     "shell.execute_reply.started": "2025-07-31T13:31:51.660025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate pre-fine-tuned models\n",
    "def evaluate_pre_finetuned_model(model_name, tokenizer_class, model_class, tokenized_datasets):\n",
    "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "    model = model_class.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length=256)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=f\"/kaggle/working/{model_name.split('/')[-1]}_prefinetuned\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            report_to=\"none\"\n",
    "        ),\n",
    "        eval_dataset=tokenized_datasets['test'],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on test set \n",
    "    test_results = trainer.evaluate()\n",
    "    print(f\"Kết quả đánh giá pre-fine-tuned model ({model_name}) trên tập test: {test_results}\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    y_pred = trainer.predict(tokenized_datasets['test']).predictions\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    y_true = tokenized_datasets['test']['labels']\n",
    "    print(f\"\\nClassification Report pre-fine-tuned ({model_name}):\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:51.682924Z",
     "iopub.status.busy": "2025-07-31T13:31:51.682678Z",
     "iopub.status.idle": "2025-07-31T13:31:51.701705Z",
     "shell.execute_reply": "2025-07-31T13:31:51.701093Z",
     "shell.execute_reply.started": "2025-07-31T13:31:51.682902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to fine-tune models\n",
    "def fine_tune_model(model_name, tokenizer_class, model_class, output_dir, tokenized_datasets):\n",
    "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "    model = model_class.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length=256)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=3,\n",
    "        eval_strategy=\"epoch\",\n",
    "        weight_decay=5e-4,\n",
    "        optim=\"adamw_torch\",\n",
    "        learning_rate=5e-5,\n",
    "        save_strategy=\"no\",\n",
    "        fp16=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['valid'],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_results = trainer.evaluate()\n",
    "    print(f\"Kết quả đánh giá fine-tuned model ({model_name}) trên tập validation: {val_results}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_results = trainer.evaluate(tokenized_datasets['test'])\n",
    "    print(f\"Kết quả đánh giá fine-tuned model ({model_name}) trên tập test: {test_results}\")\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"Mô hình fine-tuned {model_name} đã được lưu tại {output_dir}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    y_pred = trainer.predict(tokenized_datasets['test']).predictions\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    y_true = tokenized_datasets['test']['labels']\n",
    "    print(f\"\\nClassification Report fine-tuned ({model_name}):\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:51.702463Z",
     "iopub.status.busy": "2025-07-31T13:31:51.702280Z",
     "iopub.status.idle": "2025-07-31T13:31:51.725386Z",
     "shell.execute_reply": "2025-07-31T13:31:51.724895Z",
     "shell.execute_reply.started": "2025-07-31T13:31:51.702448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to tokenize data\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512, return_token_type_ids=False)\n",
    "\n",
    "# Config DistilBERT model\n",
    "distilbert_config = {\n",
    "    'model_name': \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    'tokenizer_class': DistilBertTokenizer,\n",
    "    'model_class': DistilBertForSequenceClassification,\n",
    "    'output_dir': \"/kaggle/working/distilbert_finetuned\"\n",
    "}\n",
    "\n",
    "# Config RoBERTa model\n",
    "twitter_roberta_config = {\n",
    "    'model_name': \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    'tokenizer_class': AutoTokenizer,\n",
    "    'model_class': AutoModelForSequenceClassification,\n",
    "    'output_dir': \"/kaggle/working/twitter_roberta_finetuned\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:31:51.727696Z",
     "iopub.status.busy": "2025-07-31T13:31:51.727247Z",
     "iopub.status.idle": "2025-07-31T13:33:45.195745Z",
     "shell.execute_reply": "2025-07-31T13:33:45.195215Z",
     "shell.execute_reply.started": "2025-07-31T13:31:51.727671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Xử lý DistilBERT ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b363672b6be48f681440c59074a0edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9662ec9ae7439b978554bba976055e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01be57e335a1450b86ca45f21e7e6d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac319e3d683d4d6cbff4f20a57eb5ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079ee1b672934089a43308910b005d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f6f2adbcf04faab7fef4998566873e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. DistilBERT Processing\n",
    "print(\"\\n=== Xử lý DistilBERT ===\")\n",
    "# Tokenize data for DistilBERT\n",
    "distilbert_tokenizer = distilbert_config['tokenizer_class'].from_pretrained(distilbert_config['model_name'])\n",
    "distilbert_tokenized_datasets = raw_datasets.map(lambda x: tokenize_function(x, distilbert_tokenizer), batched=True)\n",
    "distilbert_tokenized_datasets = distilbert_tokenized_datasets.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:33:45.196769Z",
     "iopub.status.busy": "2025-07-31T13:33:45.196496Z",
     "iopub.status.idle": "2025-07-31T13:36:00.597534Z",
     "shell.execute_reply": "2025-07-31T13:36:00.596649Z",
     "shell.execute_reply.started": "2025-07-31T13:33:45.196744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá pre-fine-tuned model: distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1058df6130eb457caac6f437f885a945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/1161746956.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec9cca89a284150bbdc0ca59faf7c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8894005c89c04926b2ced76b5c54de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đánh giá pre-fine-tuned model (distilbert-base-uncased-finetuned-sst-2-english) trên tập test: {'eval_loss': 0.7170329689979553, 'eval_accuracy': 0.7956, 'eval_f1': 0.7919230151894299, 'eval_runtime': 64.5374, 'eval_samples_per_second': 116.212, 'eval_steps_per_second': 7.267}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report pre-fine-tuned (distilbert-base-uncased-finetuned-sst-2-english):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.734     0.929     0.820      3750\n",
      "           1      0.903     0.663     0.764      3750\n",
      "\n",
      "    accuracy                          0.796      7500\n",
      "   macro avg      0.818     0.796     0.792      7500\n",
      "weighted avg      0.818     0.796     0.792      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pre-fine-tuned DistilBERT model\n",
    "print(\"\\nĐánh giá pre-fine-tuned model: distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "evaluate_pre_finetuned_model(\n",
    "    distilbert_config['model_name'],\n",
    "    distilbert_config['tokenizer_class'],\n",
    "    distilbert_config['model_class'],\n",
    "    distilbert_tokenized_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T13:36:00.598675Z",
     "iopub.status.busy": "2025-07-31T13:36:00.598374Z",
     "iopub.status.idle": "2025-07-31T14:32:19.795485Z",
     "shell.execute_reply": "2025-07-31T14:32:19.794740Z",
     "shell.execute_reply.started": "2025-07-31T13:36:00.598647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning model: distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/3317148887.py:85: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6564' max='6564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6564/6564 52:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.250442</td>\n",
       "      <td>0.905067</td>\n",
       "      <td>0.905063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.356700</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>0.902133</td>\n",
       "      <td>0.902126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>1.401354</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>0.906265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đánh giá fine-tuned model (distilbert-base-uncased-finetuned-sst-2-english) trên tập validation: {'eval_loss': 1.4013543128967285, 'eval_accuracy': 0.9062666666666667, 'eval_f1': 0.9062648519542005, 'eval_runtime': 68.5727, 'eval_samples_per_second': 109.373, 'eval_steps_per_second': 6.839, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đánh giá fine-tuned model (distilbert-base-uncased-finetuned-sst-2-english) trên tập test: {'eval_loss': 1.3239593505859375, 'eval_accuracy': 0.9113333333333333, 'eval_f1': 0.9113332560947476, 'eval_runtime': 68.4343, 'eval_samples_per_second': 109.594, 'eval_steps_per_second': 6.853, 'epoch': 3.0}\n",
      "Mô hình fine-tuned distilbert-base-uncased-finetuned-sst-2-english đã được lưu tại /kaggle/working/distilbert_finetuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report fine-tuned (distilbert-base-uncased-finetuned-sst-2-english):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.912     0.910     0.911      3750\n",
      "           1      0.911     0.912     0.911      3750\n",
      "\n",
      "    accuracy                          0.911      7500\n",
      "   macro avg      0.911     0.911     0.911      7500\n",
      "weighted avg      0.911     0.911     0.911      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning DistilBERT\n",
    "print(\"\\nFine-tuning model: distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "fine_tune_model(\n",
    "    distilbert_config['model_name'],\n",
    "    distilbert_config['tokenizer_class'],\n",
    "    distilbert_config['model_class'],\n",
    "    distilbert_config['output_dir'],\n",
    "    distilbert_tokenized_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T14:32:19.796752Z",
     "iopub.status.busy": "2025-07-31T14:32:19.796482Z",
     "iopub.status.idle": "2025-07-31T14:32:38.724494Z",
     "shell.execute_reply": "2025-07-31T14:32:38.723968Z",
     "shell.execute_reply.started": "2025-07-31T14:32:19.796727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Xử lý Twitter RoBERTa ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c906541580b1412ba412d67853002d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ae85e087774fb0be6a2acbb5af7790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf27d15f1f44147aff233c7c4fe77d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0672c63283004a23abba7597270f0638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3c7181d6794b67815cb0e1d7d4f719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dff18c9edad4c28ac0b51080bb32836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4734f7374ef4055a6421cb3fc2a44ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Twitter RoBERTa Processing\n",
    "print(\"\\n=== Xử lý Twitter RoBERTa ===\")\n",
    "# Tokenize data for Twitter RoBERTa\n",
    "twitter_roberta_tokenizer = twitter_roberta_config['tokenizer_class'].from_pretrained(twitter_roberta_config['model_name'])\n",
    "twitter_roberta_tokenized_datasets = raw_datasets.map(lambda x: tokenize_function(x, twitter_roberta_tokenizer), batched=True)\n",
    "twitter_roberta_tokenized_datasets = twitter_roberta_tokenized_datasets.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T14:32:38.725453Z",
     "iopub.status.busy": "2025-07-31T14:32:38.725215Z",
     "iopub.status.idle": "2025-07-31T14:37:00.595356Z",
     "shell.execute_reply": "2025-07-31T14:37:00.594565Z",
     "shell.execute_reply.started": "2025-07-31T14:32:38.725431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá pre-fine-tuned model: cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c8e8f442454f9b91e59a1a5f1dce6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_36/1161746956.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a2238dca754d5e9178f1d53cf2ca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đánh giá pre-fine-tuned model (cardiffnlp/twitter-roberta-base-sentiment-latest) trên tập test: {'eval_loss': 0.7688709497451782, 'eval_accuracy': 0.2976, 'eval_f1': 0.26086555692611063, 'eval_runtime': 128.9806, 'eval_samples_per_second': 58.148, 'eval_steps_per_second': 3.636}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report pre-fine-tuned (cardiffnlp/twitter-roberta-base-sentiment-latest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.135     0.075     0.096      3750\n",
      "           1      0.360     0.521     0.426      3750\n",
      "\n",
      "    accuracy                          0.298      7500\n",
      "   macro avg      0.247     0.298     0.261      7500\n",
      "weighted avg      0.247     0.298     0.261      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pre-fine-tuned Twitter RoBERTa model\n",
    "print(\"\\nĐánh giá pre-fine-tuned model: cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "evaluate_pre_finetuned_model(\n",
    "    twitter_roberta_config['model_name'],\n",
    "    twitter_roberta_config['tokenizer_class'],\n",
    "    twitter_roberta_config['model_class'],\n",
    "    twitter_roberta_tokenized_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T14:37:00.596395Z",
     "iopub.status.busy": "2025-07-31T14:37:00.596110Z",
     "iopub.status.idle": "2025-07-31T16:27:08.092242Z",
     "shell.execute_reply": "2025-07-31T16:27:08.091641Z",
     "shell.execute_reply.started": "2025-07-31T14:37:00.596362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning model: cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_36/3317148887.py:85: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6564' max='6564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6564/6564 1:43:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.288700</td>\n",
       "      <td>0.288155</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.901302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.351296</td>\n",
       "      <td>0.911200</td>\n",
       "      <td>0.911192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>1.190983</td>\n",
       "      <td>0.916400</td>\n",
       "      <td>0.916389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đánh giá fine-tuned model (cardiffnlp/twitter-roberta-base-sentiment-latest) trên tập validation: {'eval_loss': 1.1909832954406738, 'eval_accuracy': 0.9164, 'eval_f1': 0.9163892606650366, 'eval_runtime': 126.8, 'eval_samples_per_second': 59.148, 'eval_steps_per_second': 3.699, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đánh giá fine-tuned model (cardiffnlp/twitter-roberta-base-sentiment-latest) trên tập test: {'eval_loss': 1.086658239364624, 'eval_accuracy': 0.9237333333333333, 'eval_f1': 0.9237321130471421, 'eval_runtime': 126.9619, 'eval_samples_per_second': 59.073, 'eval_steps_per_second': 3.694, 'epoch': 3.0}\n",
      "Mô hình fine-tuned cardiffnlp/twitter-roberta-base-sentiment-latest đã được lưu tại /kaggle/working/twitter_roberta_finetuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report fine-tuned (cardiffnlp/twitter-roberta-base-sentiment-latest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.920     0.928     0.924      3750\n",
      "           1      0.927     0.920     0.923      3750\n",
      "\n",
      "    accuracy                          0.924      7500\n",
      "   macro avg      0.924     0.924     0.924      7500\n",
      "weighted avg      0.924     0.924     0.924      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Twitter RoBERTa\n",
    "print(\"\\nFine-tuning model: cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "fine_tune_model(\n",
    "    twitter_roberta_config['model_name'],\n",
    "    twitter_roberta_config['tokenizer_class'],\n",
    "    twitter_roberta_config['model_class'],\n",
    "    twitter_roberta_config['output_dir'],\n",
    "    twitter_roberta_tokenized_datasets\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7919180,
     "sourceId": 12543401,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
